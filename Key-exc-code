import nltk
from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

nltk.download('punkt')
nltk.download('stopwords')

with open("sample_text.txt", "r") as file:
    text = file.read()

words = word_tokenize(text.lower())
filtered_words = [w for w in words if w.isalpha() and w not in stopwords.words("english")]
most_common = Counter(filtered_words).most_common(10)

print("Top 10 Keywords:")
for word, freq in most_common:
    print(f"{word}: {freq}")
